{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f57fc77-a258-4159-82f1-f09bf01a9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f890c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e98d9cb-55b5-45cb-9a67-e4527e69a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc109e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-h1O9PvOERwpNx2vAbORqT3BlbkFJBxRxEBVPpCMEDGPAs6Sd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3bf681b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4558f4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2124634d02844848c22c576461cff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5845538c15b421a9e4904aeeffd04da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "731f37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_prompt = \"You are a pizza ordering assistant,users would give you the orders, your task is to based on the readme, create a request fillig the data based on the readme. return endpoints based on the provided documents. return the response as endpoint: ' ', endpoint body : {}, query param : \"\n",
    "base_prompt = \"\"\"\n",
    "You are a pizza ordering assistant. Your task is to take input from the user based on their requirements and return the endpoint and its needed parameters from the user input in the following format:\n",
    "Endpoint: [API endpoint URL]\n",
    "Request Body: [JSON or other structured format]\n",
    "Request Parameters: [URL parameters]\n",
    "If something is missing, request the necessary information from the user.\n",
    "OR\n",
    "answer like a normal human if that does not match with the query\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3b2afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \" You are a pizza ordering assistant help the user to choose and order pizza from the pizza menu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6df7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(base_prompt = base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69895463",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"I would like to know the list of pizza available here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f92cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available pizzas are Margherita, Pepperoni, Veggie, BBQ Chicken, Hawaiian, and Meat Lovers.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4ba8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.retrievers import SummaryIndexLLMRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "88b0034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorIndexRetriever(index=index, top_k=5)\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b6c7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(f\"{base_prompt}\" + \"Great I would like to go with margherita and spinach for toppings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "384e832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! You've selected the Margherita pizza from the Classic Pizzas category. For toppings, you've chosen spinach. Enjoy your delicious pizza!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d5340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
